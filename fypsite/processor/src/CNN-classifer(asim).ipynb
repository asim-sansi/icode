{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "name": "first_CNN_model.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkWpfFarrH9n",
    "colab_type": "text"
   },
   "source": [
    "## Training your first Convolutional Neural Network with Keras\n",
    "## Run on colab to aviod any dependency issues"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vSRW12h9rH9u",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# A simple feedforward neural network to classify images can be improved by leveraging \n",
    "# on Convolutional Neural Networks (CNNs) which are designed to operate over the raw pixel intensities of images \n",
    "# and learn discriminating filters that can be used to classify images with high accuracy\n",
    "\n",
    "# VGGNet-like models share two common characteristics:\n",
    "# * Only 3×3 convolutions are used\n",
    "# * Convolution layers are stacked on top of each other deeper in the network architecture prior to applying a destructive pooling operation\n",
    "\n",
    "# The model we’ll be discussing here today is a smaller variant of VGGNet which I have named “SmallVGGNet”."
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iW2MeUIarPha",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "outputId": "19457ab0-a073-4e31-8899-c44651e90d4f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826090322,
     "user_tz": -300,
     "elapsed": 41780,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# # Mounting Drive, downloading and extracting training data images\n",
    "\n",
    "# !pip install -U -q PyDrive\n",
    "\n",
    "# zip_id = '1nyDSB8TOqGE1BlefUaW5yKvLx5mIUOu_'\n",
    "\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# import zipfile, os\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "# print ('Downloading zip file')\n",
    "# myzip = drive.CreateFile({'id': zip_id})\n",
    "# myzip.GetContentFile('dataset1.zip')\n",
    "\n",
    "# print('uncompressing zip file')\n",
    "# zip_ref = zipfile.ZipFile('dataset1.zip', 'r')\n",
    "# zip_ref.extractall('gdrive')\n",
    "# zip_ref.close()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Downloading zip file\n",
      "uncompressing zip file\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VjqRZwvXrn_9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "bdc1c20d-7733-491d-bb08-760d7ea133d6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582824523894,
     "user_tz": -300,
     "elapsed": 3985,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# !ls 'gdrive/data_try_1'"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "a  button  form  img  inputtext  ul\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KwtZzDMtroOG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eClzyPqfrPxN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdjcB7eOrH-E",
    "colab_type": "text"
   },
   "source": [
    "### to implement SmallVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p3-3J76zrH-J",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "outputId": "c347689c-c970-447c-db7b-68d88615d12a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826183627,
     "user_tz": -300,
     "elapsed": 2244,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# smallvggnet.py\n",
    "\n",
    "# import the necessary packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# define our SmallVGGNet class and the build method\n",
    "# Should I use \"ELU\" for hidden layer as better for image classification?\n",
    "class SmallVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model along with the input shape to be \"channels last\" and the channels dimension/depth itself\n",
    "        model = Sequential()   # (i.e. TensorFlow ordering)\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":   # (i.e. Theano ordering)\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "\n",
    "        # CONV => RELU => POOL layer set              # first CONV layer has 32 filters of size 3x3\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))                 # ReLU (Rectified Linear Unit) activation function\n",
    "        model.add(BatchNormalization(axis=chanDim))   # normalize activations of input volume before passing to next layer\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))     # progressively reduce spatial size (width and height) of input \n",
    "        model.add(Dropout(0.25))                      # disconnecting random neurons between layers, reduce overfitting\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL layer set          # filter dimensions remain the same (3x3)\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))   # increase total number of filters learned (from 32 to 64)\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # (CONV => RELU) * 3 => POOL layer set\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))   # total number of filters learned by CONV layers has doubled (128)\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # first (and only) set of fully connected layer (FC) => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gdJHT2NfrH-e",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Now that SmallVGGNet is implemented, let’s write the driver script that will be used to train it on our Animals dataset"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "942ngIyrrH-4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# import the necessary packages\n",
    "# from pyimagesearch.smallvggnet import SmallVGGNet   # \"smallvggnet.py\" file is in \"pyimagesearch\" folder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QzOEj3hyrH_V",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# import pandas as pd\n",
    "# data= pd.read_csv('billlabels.csv')\n",
    "# data=data.drop('Unnamed: 0',1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QUlDMjvRrH_z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9xfsLCXyrIAF",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "outputId": "bfb3b563-023a-43ca-e02b-d409e406879c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826213716,
     "user_tz": -300,
     "elapsed": 16299,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "\n",
    "folders = ['a', 'button', 'form', 'img', 'inputtext', 'ul']\n",
    "for i in folders:\n",
    "  imagePaths = sorted(list(paths.list_images('gdrive/data_try_1/'+i)))\n",
    "  random.seed(42)\n",
    "  random.shuffle(imagePaths)\n",
    "\n",
    "  # loop over the input images\n",
    "  for imagePath in imagePaths:\n",
    "      # load the image, resize it to 64x64 pixels (the required input spatial dimensions of SmallVGGNet), \n",
    "      # and store the image in the data list\n",
    "      image = cv2.imread(imagePath)\n",
    "      image = cv2.resize(image, (64, 64))   # we are not flattening our data for neural network, because it is convolutional\n",
    "      images.append(image)\n",
    "      # print (imagePath)\n",
    "      name=imagePath.split('/')[3]\n",
    "      # extract the class label from the image path and update the labels list\n",
    "      labels.append(i)\n",
    "    \n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "images = np.array(images, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('done')"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "done\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rM5_ntcbrIAR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "f41133fd-69c3-4a83-9bce-a76a21b83eb5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826221711,
     "user_tz": -300,
     "elapsed": 879,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# partition the data into 75% training and 25% validation, try 80/20 later\n",
    "(trainX, testX, trainY, testY) = train_test_split(images,labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# before transformation\n",
    "trainY"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['a', 'img', 'form', ..., 'form', 'a', 'img'], dtype='<U9')"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pgzhtxRF1mH8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "8078c306-a946-4a77-b6f8-bf50b0fb549f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826979426,
     "user_tz": -300,
     "elapsed": 775,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "testY[1]"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HagNFUTVrIAf",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "919abc0a-76e2-4170-f0a7-d0d216941440",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826230599,
     "user_tz": -300,
     "elapsed": 790,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "trainY.shape"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10164,)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s8s3n3h_rIAq",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "outputId": "823048e6-b57c-4981-c9c6-67ccc19c4084",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826247504,
     "user_tz": -300,
     "elapsed": 824,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# convert the labels from integers to vectors \n",
    "# (for 2-class, binary classification you should use Keras' to_categorical function)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# after transformation\n",
    "trainY"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0]])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "xIVbI6nQrIA4",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "395bcf8e-4d7e-4bb7-8da8-01abd14f8b00",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826836631,
     "user_tz": -300,
     "elapsed": 579558,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# Construct & initialize the image data generator for data augmentation\n",
    "# Image augmentation allows us to construct “additional” training data from our existing training data \n",
    "# by randomly rotating, shifting, shearing, zooming, and flipping. This is to avoid overfitting.\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=64, height=64, depth=3, classes=len(lb.classes_))\n",
    "\n",
    "# compile & train model\n",
    "# initialize our initial learning rate, # of epochs to train for, and batch size\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "BS = 16\n",
    "\n",
    "# initialize the model and optimizer (you'll want to use binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "H = model.fit_generator( aug.flow(trainX, trainY, batch_size=BS),\n",
    "                        validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS, epochs=EPOCHS,\n",
    "                        callbacks=[keras.callbacks.EarlyStopping(patience=11, verbose=1, restore_best_weights=True),\n",
    "                                   keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)] )"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/75\n",
      "635/635 [==============================] - 26s 41ms/step - loss: 1.6663 - acc: 0.4508 - val_loss: 2.3743 - val_acc: 0.2274\n",
      "Epoch 2/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 1.1164 - acc: 0.6102 - val_loss: 2.0188 - val_acc: 0.5035\n",
      "Epoch 3/75\n",
      "635/635 [==============================] - 17s 28ms/step - loss: 0.9695 - acc: 0.6532 - val_loss: 1.0260 - val_acc: 0.6106\n",
      "Epoch 4/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.8729 - acc: 0.6872 - val_loss: 1.3545 - val_acc: 0.6204\n",
      "Epoch 5/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.8032 - acc: 0.7133 - val_loss: 0.6454 - val_acc: 0.7478\n",
      "Epoch 6/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.7439 - acc: 0.7391 - val_loss: 2.3607 - val_acc: 0.4487\n",
      "Epoch 7/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.7228 - acc: 0.7488 - val_loss: 0.8528 - val_acc: 0.7027\n",
      "Epoch 8/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.6861 - acc: 0.7569 - val_loss: 1.0019 - val_acc: 0.6566\n",
      "Epoch 9/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.6476 - acc: 0.7708 - val_loss: 2.5297 - val_acc: 0.4558\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 10/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.5956 - acc: 0.7921 - val_loss: 0.5256 - val_acc: 0.7991\n",
      "Epoch 11/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.5772 - acc: 0.7992 - val_loss: 0.5316 - val_acc: 0.8044\n",
      "Epoch 12/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.5501 - acc: 0.8102 - val_loss: 0.8194 - val_acc: 0.7496\n",
      "Epoch 13/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.5597 - acc: 0.8004 - val_loss: 0.4968 - val_acc: 0.8345\n",
      "Epoch 14/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.5394 - acc: 0.8150 - val_loss: 0.5754 - val_acc: 0.7947\n",
      "Epoch 15/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.5300 - acc: 0.8182 - val_loss: 0.4953 - val_acc: 0.8009\n",
      "Epoch 16/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.5276 - acc: 0.8145 - val_loss: 0.3746 - val_acc: 0.8814\n",
      "Epoch 17/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.5116 - acc: 0.8206 - val_loss: 1.0528 - val_acc: 0.7009\n",
      "Epoch 18/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.5226 - acc: 0.8177 - val_loss: 0.3880 - val_acc: 0.8770\n",
      "Epoch 19/75\n",
      "635/635 [==============================] - 17s 28ms/step - loss: 0.4963 - acc: 0.8235 - val_loss: 0.3816 - val_acc: 0.8779\n",
      "Epoch 20/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.4906 - acc: 0.8272 - val_loss: 0.6470 - val_acc: 0.7487\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 21/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4755 - acc: 0.8359 - val_loss: 0.3574 - val_acc: 0.8841\n",
      "Epoch 22/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4719 - acc: 0.8382 - val_loss: 0.4545 - val_acc: 0.8257\n",
      "Epoch 23/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.4731 - acc: 0.8379 - val_loss: 0.4629 - val_acc: 0.8354\n",
      "Epoch 24/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4689 - acc: 0.8354 - val_loss: 0.4564 - val_acc: 0.8195\n",
      "Epoch 25/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4583 - acc: 0.8417 - val_loss: 0.4775 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 26/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4542 - acc: 0.8406 - val_loss: 0.3797 - val_acc: 0.8708\n",
      "Epoch 27/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.4588 - acc: 0.8404 - val_loss: 0.3578 - val_acc: 0.8823\n",
      "Epoch 28/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.4557 - acc: 0.8425 - val_loss: 0.4088 - val_acc: 0.8504\n",
      "Epoch 29/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4555 - acc: 0.8430 - val_loss: 0.3702 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 30/75\n",
      "635/635 [==============================] - 18s 28ms/step - loss: 0.4483 - acc: 0.8437 - val_loss: 0.3806 - val_acc: 0.8611\n",
      "Epoch 31/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4575 - acc: 0.8422 - val_loss: 0.4640 - val_acc: 0.8274\n",
      "Epoch 32/75\n",
      "635/635 [==============================] - 17s 27ms/step - loss: 0.4476 - acc: 0.8424 - val_loss: 0.3798 - val_acc: 0.8673\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00032: early stopping\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CzFCdAdzrIBM",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "outputId": "abc47a48-772a-4673-af55-5d640db8de64",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826884945,
     "user_tz": -300,
     "elapsed": 1183,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=16)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.82      0.78      0.80       242\n",
      "      button       0.84      0.95      0.89       164\n",
      "        form       0.99      1.00      0.99       205\n",
      "         img       0.88      0.80      0.84       169\n",
      "   inputtext       0.96      0.89      0.92       168\n",
      "          ul       0.84      0.91      0.87       182\n",
      "\n",
      "    accuracy                           0.88      1130\n",
      "   macro avg       0.89      0.89      0.89      1130\n",
      "weighted avg       0.89      0.88      0.88      1130\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O6Snu_1mrIBZ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "a451a02e-69ed-4a8c-8101-b0eb09106dda",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582826906675,
     "user_tz": -300,
     "elapsed": 817,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "i=predictions[1].argmax()\n",
    "label = lb.classes_[i]\n",
    "label"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'form'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AY53v3TzrIBi",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "6c60419f-c4bd-4b48-f90f-edf4015984dc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582827013765,
     "user_tz": -300,
     "elapsed": 918,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "lis=[]\n",
    "for j in predictions:\n",
    "    i = j.argmax()\n",
    "    label = lb.classes_[i]\n",
    "    lis.append(label)\n",
    "    print(label)\n",
    "#i = predictions.argmax(axis=1)[0]\n",
    "#label = lb.classes_[i]"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "button\n",
      "form\n",
      "ul\n",
      "a\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "img\n",
      "ul\n",
      "a\n",
      "form\n",
      "button\n",
      "form\n",
      "form\n",
      "a\n",
      "img\n",
      "ul\n",
      "form\n",
      "img\n",
      "a\n",
      "ul\n",
      "button\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "a\n",
      "button\n",
      "ul\n",
      "ul\n",
      "a\n",
      "ul\n",
      "ul\n",
      "img\n",
      "a\n",
      "a\n",
      "ul\n",
      "button\n",
      "img\n",
      "a\n",
      "img\n",
      "button\n",
      "button\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "ul\n",
      "a\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "a\n",
      "a\n",
      "button\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "button\n",
      "ul\n",
      "img\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "a\n",
      "ul\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "ul\n",
      "a\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "ul\n",
      "a\n",
      "a\n",
      "button\n",
      "form\n",
      "img\n",
      "button\n",
      "form\n",
      "ul\n",
      "img\n",
      "form\n",
      "img\n",
      "img\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "button\n",
      "ul\n",
      "a\n",
      "ul\n",
      "a\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "ul\n",
      "form\n",
      "button\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "a\n",
      "inputtext\n",
      "img\n",
      "a\n",
      "img\n",
      "button\n",
      "form\n",
      "img\n",
      "a\n",
      "img\n",
      "img\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "a\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "a\n",
      "button\n",
      "form\n",
      "img\n",
      "img\n",
      "a\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "button\n",
      "a\n",
      "a\n",
      "button\n",
      "ul\n",
      "a\n",
      "button\n",
      "a\n",
      "button\n",
      "img\n",
      "button\n",
      "a\n",
      "ul\n",
      "a\n",
      "img\n",
      "form\n",
      "a\n",
      "form\n",
      "a\n",
      "form\n",
      "img\n",
      "img\n",
      "ul\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "img\n",
      "ul\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "form\n",
      "img\n",
      "ul\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "button\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "form\n",
      "button\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "ul\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "a\n",
      "img\n",
      "ul\n",
      "button\n",
      "ul\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "button\n",
      "img\n",
      "button\n",
      "form\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "form\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "img\n",
      "a\n",
      "a\n",
      "img\n",
      "a\n",
      "a\n",
      "ul\n",
      "ul\n",
      "form\n",
      "img\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "button\n",
      "button\n",
      "form\n",
      "a\n",
      "a\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "a\n",
      "a\n",
      "img\n",
      "ul\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "button\n",
      "ul\n",
      "img\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "a\n",
      "img\n",
      "ul\n",
      "form\n",
      "form\n",
      "img\n",
      "button\n",
      "img\n",
      "form\n",
      "button\n",
      "ul\n",
      "a\n",
      "ul\n",
      "img\n",
      "a\n",
      "img\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "button\n",
      "button\n",
      "img\n",
      "a\n",
      "img\n",
      "img\n",
      "ul\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "form\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "button\n",
      "button\n",
      "img\n",
      "form\n",
      "button\n",
      "form\n",
      "form\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "a\n",
      "form\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "img\n",
      "ul\n",
      "button\n",
      "a\n",
      "ul\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "button\n",
      "form\n",
      "ul\n",
      "ul\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "a\n",
      "img\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "ul\n",
      "a\n",
      "ul\n",
      "button\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "button\n",
      "img\n",
      "img\n",
      "form\n",
      "a\n",
      "img\n",
      "img\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "img\n",
      "a\n",
      "button\n",
      "a\n",
      "button\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "ul\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "a\n",
      "ul\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "form\n",
      "ul\n",
      "button\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "form\n",
      "button\n",
      "img\n",
      "form\n",
      "form\n",
      "form\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "form\n",
      "a\n",
      "ul\n",
      "button\n",
      "button\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "a\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "a\n",
      "img\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "form\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "a\n",
      "form\n",
      "form\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "img\n",
      "button\n",
      "button\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "a\n",
      "form\n",
      "img\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "ul\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "img\n",
      "button\n",
      "form\n",
      "ul\n",
      "ul\n",
      "button\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "a\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "form\n",
      "form\n",
      "form\n",
      "ul\n",
      "a\n",
      "form\n",
      "ul\n",
      "a\n",
      "button\n",
      "ul\n",
      "button\n",
      "img\n",
      "img\n",
      "a\n",
      "button\n",
      "ul\n",
      "form\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "button\n",
      "button\n",
      "form\n",
      "form\n",
      "ul\n",
      "form\n",
      "a\n",
      "ul\n",
      "button\n",
      "button\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "form\n",
      "button\n",
      "form\n",
      "button\n",
      "ul\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "form\n",
      "button\n",
      "img\n",
      "button\n",
      "form\n",
      "ul\n",
      "img\n",
      "button\n",
      "ul\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "form\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "img\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "a\n",
      "ul\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "ul\n",
      "form\n",
      "form\n",
      "ul\n",
      "button\n",
      "form\n",
      "ul\n",
      "a\n",
      "a\n",
      "button\n",
      "img\n",
      "img\n",
      "form\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "form\n",
      "form\n",
      "ul\n",
      "img\n",
      "button\n",
      "form\n",
      "a\n",
      "form\n",
      "ul\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "ul\n",
      "button\n",
      "a\n",
      "button\n",
      "ul\n",
      "img\n",
      "form\n",
      "a\n",
      "form\n",
      "button\n",
      "button\n",
      "form\n",
      "ul\n",
      "ul\n",
      "form\n",
      "form\n",
      "a\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "button\n",
      "form\n",
      "img\n",
      "img\n",
      "form\n",
      "button\n",
      "a\n",
      "form\n",
      "button\n",
      "ul\n",
      "img\n",
      "form\n",
      "a\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "form\n",
      "button\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "form\n",
      "button\n",
      "img\n",
      "button\n",
      "a\n",
      "img\n",
      "button\n",
      "img\n",
      "a\n",
      "button\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "form\n",
      "button\n",
      "form\n",
      "button\n",
      "button\n",
      "a\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "img\n",
      "ul\n",
      "ul\n",
      "button\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "a\n",
      "form\n",
      "img\n",
      "img\n",
      "button\n",
      "a\n",
      "img\n",
      "form\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "img\n",
      "ul\n",
      "button\n",
      "ul\n",
      "form\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "img\n",
      "form\n",
      "ul\n",
      "a\n",
      "a\n",
      "img\n",
      "a\n",
      "ul\n",
      "form\n",
      "img\n",
      "img\n",
      "a\n",
      "form\n",
      "a\n",
      "form\n",
      "img\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "form\n",
      "form\n",
      "img\n",
      "ul\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "button\n",
      "a\n",
      "form\n",
      "ul\n",
      "ul\n",
      "a\n",
      "img\n",
      "img\n",
      "a\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "button\n",
      "img\n",
      "ul\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "button\n",
      "img\n",
      "button\n",
      "ul\n",
      "ul\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "button\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "button\n",
      "form\n",
      "a\n",
      "ul\n",
      "img\n",
      "button\n",
      "a\n",
      "form\n",
      "button\n",
      "a\n",
      "a\n",
      "a\n",
      "button\n",
      "ul\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "img\n",
      "a\n",
      "img\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "button\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "button\n",
      "ul\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "a\n",
      "ul\n",
      "button\n",
      "button\n",
      "img\n",
      "a\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "form\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "a\n",
      "ul\n",
      "button\n",
      "img\n",
      "form\n",
      "ul\n",
      "img\n",
      "form\n",
      "button\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "a\n",
      "button\n",
      "ul\n",
      "a\n",
      "button\n",
      "a\n",
      "form\n",
      "a\n",
      "button\n",
      "form\n",
      "a\n",
      "img\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "img\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "inputtext\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_bG4GEqsrIBu",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "d6fe285b-0eae-4f73-eb3a-36cdfff9cd74",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582827030398,
     "user_tz": -300,
     "elapsed": 1025,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "lis1=[]\n",
    "for j in testY:\n",
    "    i = j.argmax()\n",
    "    label = lb.classes_[i]\n",
    "    lis1.append(label)\n",
    "    print(label)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "button\n",
      "form\n",
      "ul\n",
      "a\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "img\n",
      "ul\n",
      "a\n",
      "form\n",
      "a\n",
      "form\n",
      "form\n",
      "a\n",
      "img\n",
      "ul\n",
      "form\n",
      "img\n",
      "a\n",
      "img\n",
      "button\n",
      "a\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "a\n",
      "button\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "ul\n",
      "img\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "img\n",
      "a\n",
      "img\n",
      "button\n",
      "button\n",
      "a\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "inputtext\n",
      "button\n",
      "ul\n",
      "ul\n",
      "a\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "img\n",
      "a\n",
      "a\n",
      "button\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "a\n",
      "ul\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "ul\n",
      "a\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "ul\n",
      "a\n",
      "a\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "ul\n",
      "img\n",
      "form\n",
      "img\n",
      "img\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "button\n",
      "ul\n",
      "a\n",
      "ul\n",
      "img\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "img\n",
      "form\n",
      "button\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "img\n",
      "inputtext\n",
      "img\n",
      "button\n",
      "a\n",
      "button\n",
      "form\n",
      "img\n",
      "a\n",
      "img\n",
      "img\n",
      "button\n",
      "form\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "a\n",
      "button\n",
      "form\n",
      "img\n",
      "img\n",
      "a\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "img\n",
      "button\n",
      "a\n",
      "a\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "button\n",
      "img\n",
      "button\n",
      "a\n",
      "ul\n",
      "a\n",
      "img\n",
      "form\n",
      "a\n",
      "form\n",
      "a\n",
      "form\n",
      "img\n",
      "a\n",
      "ul\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "img\n",
      "ul\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "form\n",
      "img\n",
      "ul\n",
      "form\n",
      "ul\n",
      "button\n",
      "img\n",
      "a\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "form\n",
      "button\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "ul\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "img\n",
      "ul\n",
      "button\n",
      "ul\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "button\n",
      "img\n",
      "button\n",
      "form\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "img\n",
      "a\n",
      "a\n",
      "img\n",
      "img\n",
      "a\n",
      "ul\n",
      "ul\n",
      "form\n",
      "a\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "a\n",
      "ul\n",
      "button\n",
      "ul\n",
      "button\n",
      "form\n",
      "a\n",
      "img\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "a\n",
      "a\n",
      "img\n",
      "ul\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "button\n",
      "ul\n",
      "img\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "a\n",
      "img\n",
      "ul\n",
      "form\n",
      "form\n",
      "img\n",
      "button\n",
      "img\n",
      "form\n",
      "button\n",
      "img\n",
      "a\n",
      "ul\n",
      "img\n",
      "a\n",
      "img\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "ul\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "button\n",
      "button\n",
      "img\n",
      "img\n",
      "img\n",
      "img\n",
      "ul\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "button\n",
      "button\n",
      "img\n",
      "form\n",
      "button\n",
      "form\n",
      "form\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "a\n",
      "form\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "button\n",
      "a\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "form\n",
      "form\n",
      "a\n",
      "form\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "a\n",
      "img\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "img\n",
      "img\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "button\n",
      "img\n",
      "img\n",
      "form\n",
      "a\n",
      "button\n",
      "img\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "img\n",
      "a\n",
      "ul\n",
      "img\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "a\n",
      "a\n",
      "ul\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "a\n",
      "ul\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "img\n",
      "a\n",
      "ul\n",
      "ul\n",
      "a\n",
      "ul\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "form\n",
      "a\n",
      "button\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "form\n",
      "button\n",
      "img\n",
      "form\n",
      "form\n",
      "form\n",
      "a\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "form\n",
      "button\n",
      "ul\n",
      "button\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "a\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "a\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "a\n",
      "form\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "a\n",
      "form\n",
      "form\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "img\n",
      "button\n",
      "button\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "a\n",
      "form\n",
      "img\n",
      "a\n",
      "inputtext\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "img\n",
      "button\n",
      "form\n",
      "ul\n",
      "ul\n",
      "button\n",
      "button\n",
      "button\n",
      "form\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "a\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "a\n",
      "form\n",
      "ul\n",
      "a\n",
      "button\n",
      "ul\n",
      "button\n",
      "img\n",
      "img\n",
      "button\n",
      "button\n",
      "ul\n",
      "form\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "form\n",
      "form\n",
      "ul\n",
      "form\n",
      "img\n",
      "ul\n",
      "a\n",
      "button\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "img\n",
      "form\n",
      "button\n",
      "form\n",
      "button\n",
      "ul\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "form\n",
      "button\n",
      "img\n",
      "button\n",
      "form\n",
      "ul\n",
      "img\n",
      "button\n",
      "a\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "form\n",
      "button\n",
      "form\n",
      "ul\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "img\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "img\n",
      "ul\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "form\n",
      "ul\n",
      "form\n",
      "form\n",
      "a\n",
      "button\n",
      "form\n",
      "img\n",
      "a\n",
      "a\n",
      "button\n",
      "img\n",
      "img\n",
      "form\n",
      "ul\n",
      "a\n",
      "a\n",
      "form\n",
      "form\n",
      "ul\n",
      "img\n",
      "a\n",
      "form\n",
      "img\n",
      "form\n",
      "ul\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "ul\n",
      "button\n",
      "img\n",
      "button\n",
      "ul\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "button\n",
      "form\n",
      "ul\n",
      "img\n",
      "form\n",
      "form\n",
      "a\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "button\n",
      "form\n",
      "img\n",
      "img\n",
      "form\n",
      "button\n",
      "a\n",
      "form\n",
      "button\n",
      "ul\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "img\n",
      "inputtext\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "ul\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "button\n",
      "ul\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "form\n",
      "a\n",
      "img\n",
      "button\n",
      "img\n",
      "img\n",
      "a\n",
      "img\n",
      "a\n",
      "button\n",
      "img\n",
      "form\n",
      "form\n",
      "button\n",
      "form\n",
      "button\n",
      "form\n",
      "img\n",
      "button\n",
      "a\n",
      "ul\n",
      "form\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "img\n",
      "ul\n",
      "ul\n",
      "a\n",
      "button\n",
      "form\n",
      "inputtext\n",
      "button\n",
      "form\n",
      "a\n",
      "form\n",
      "img\n",
      "img\n",
      "a\n",
      "a\n",
      "img\n",
      "form\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "a\n",
      "ul\n",
      "img\n",
      "ul\n",
      "button\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "img\n",
      "form\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "a\n",
      "ul\n",
      "form\n",
      "a\n",
      "img\n",
      "img\n",
      "form\n",
      "ul\n",
      "form\n",
      "a\n",
      "a\n",
      "inputtext\n",
      "ul\n",
      "img\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "form\n",
      "form\n",
      "img\n",
      "a\n",
      "ul\n",
      "a\n",
      "inputtext\n",
      "a\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "a\n",
      "ul\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "ul\n",
      "a\n",
      "img\n",
      "ul\n",
      "ul\n",
      "form\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "inputtext\n",
      "img\n",
      "a\n",
      "img\n",
      "ul\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "a\n",
      "form\n",
      "a\n",
      "img\n",
      "button\n",
      "ul\n",
      "ul\n",
      "form\n",
      "inputtext\n",
      "inputtext\n",
      "ul\n",
      "a\n",
      "a\n",
      "button\n",
      "form\n",
      "button\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "button\n",
      "img\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "a\n",
      "form\n",
      "ul\n",
      "ul\n",
      "img\n",
      "button\n",
      "inputtext\n",
      "form\n",
      "button\n",
      "a\n",
      "a\n",
      "a\n",
      "button\n",
      "ul\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "img\n",
      "a\n",
      "img\n",
      "form\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "button\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "button\n",
      "ul\n",
      "button\n",
      "inputtext\n",
      "ul\n",
      "ul\n",
      "ul\n",
      "a\n",
      "button\n",
      "img\n",
      "a\n",
      "img\n",
      "form\n",
      "inputtext\n",
      "a\n",
      "button\n",
      "form\n",
      "a\n",
      "ul\n",
      "form\n",
      "button\n",
      "img\n",
      "a\n",
      "a\n",
      "button\n",
      "img\n",
      "form\n",
      "ul\n",
      "img\n",
      "form\n",
      "button\n",
      "button\n",
      "a\n",
      "inputtext\n",
      "form\n",
      "ul\n",
      "ul\n",
      "button\n",
      "ul\n",
      "a\n",
      "button\n",
      "a\n",
      "form\n",
      "a\n",
      "button\n",
      "form\n",
      "a\n",
      "img\n",
      "form\n",
      "a\n",
      "a\n",
      "form\n",
      "img\n",
      "ul\n",
      "form\n",
      "ul\n",
      "a\n",
      "a\n",
      "a\n",
      "ul\n",
      "img\n",
      "img\n",
      "ul\n",
      "inputtext\n",
      "ul\n",
      "form\n",
      "inputtext\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UBZH58R42AtT",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "a971c6b3-7514-4f2e-c243-879812b6f121",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582827061248,
     "user_tz": -300,
     "elapsed": 787,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "testY.shape"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1130, 6)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ba-pTlDHrIB5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "09fc3d31-67f8-4228-de09-225793b37e64",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582827070713,
     "user_tz": -300,
     "elapsed": 1101,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "count=0\n",
    "s=0\n",
    "for j in lis:\n",
    "    if j==lis1[s]:\n",
    "        count+=1\n",
    "    s+=1\n",
    "print(count/1130)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0.8840707964601769\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vIh7FVwvrICD",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "outputId": "3b1a4657-10f5-4d6c-a44f-ef5043743116",
    "executionInfo": {
     "status": "error",
     "timestamp": 1582827094144,
     "user_tz": -300,
     "elapsed": 2641,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(testY, predictions))\n",
    "\n",
    "# # Print confusion matrix heatmap for SmallVGGNet_CNN_model\n",
    "# knn_confusion = confusion_matrix(testY, predictions)\n",
    "# plt.figure(dpi=150)\n",
    "# sns.heatmap(knn_confusion, cmap=plt.cm.Blues, annot=True, square=True,\n",
    "#            xticklabels=['Cat', 'Dog', 'Panda'],\n",
    "#            yticklabels=['Cat', 'Dog', 'Panda'] )\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.title('SmallVGGNet_CNN confusion matrix');"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4750e484813e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# # Print confusion matrix heatmap for SmallVGGNet_CNN_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# knn_confusion = confusion_matrix(testY, predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bM9TGbNrrICM",
    "colab_type": "code",
    "colab": {},
    "outputId": "456ce84b-944c-4606-f1bb-8c7449000bf3"
   },
   "source": [
    "# visualize confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.ylabel('Actual label', weight='bold')\n",
    "plt.xlabel('Predicted label', weight='bold')\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "tick_marks = np.arange(len(iris.target_names))\n",
    "plt.xticks(tick_marks, iris.target_names, rotation=0)\n",
    "plt.yticks(tick_marks, iris.target_names)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-887d9d4231dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualize confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Actual label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C6amOc-9rICS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# for early stopping, change this value to the Epoch number stopped\n",
    "# EPOCHS = 36"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "KBsEU6JDrICY",
    "colab_type": "code",
    "colab": {},
    "outputId": "68e27670-96e1-4283-8bad-77b264c22521"
   },
   "source": [
    "# plot the training/validation loss\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = [8,6])\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and Validation Loss (first_CNN_model)\")\n",
    "plt.xlabel(\"Epoch #\", weight='bold')\n",
    "plt.ylabel(\"Loss\", weight='bold')\n",
    "plt.legend()"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ac3daef14b58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ggplot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training and Validation Loss (first_CNN_model)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKqUrf6-rICg",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "hHFoRlMErICh",
    "colab_type": "code",
    "colab": {},
    "outputId": "2edf829a-8e30-45dd-e7e0-f30f3b982c78"
   },
   "source": [
    "# plot the training/validation accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = [8,6])\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training and Validation Accuracy (first_CNN_model)\")\n",
    "plt.xlabel(\"Epoch #\", weight='bold')\n",
    "plt.ylabel(\"Accuracy\", weight='bold')\n",
    "plt.legend()"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5327914db796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ggplot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training and Validation Accuracy (first_CNN_model)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df9NPHsGrICr",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yOk8TpS3rICt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# As our results demonstrate, you can see that we are achieving 76% accuracy on our Animals dataset \n",
    "# using a Convolutional Neural Network, significantly higher than the previous accuracy of 61% using a \n",
    "# standard fully-connected network."
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "KdCGCcikrIC0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "a0b1a90f-f772-44e2-812b-1398752be6aa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582827109748,
     "user_tz": -300,
     "elapsed": 911,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 3078      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 4,627,462\n",
      "Trainable params: 4,625,350\n",
      "Non-trainable params: 2,112\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NLkSkpW6rIC6",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "1712122d-905a-4c95-84d4-acc92e3e82e9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582827175649,
     "user_tz": -300,
     "elapsed": 1391,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"gdrive/data_try_1/first_CNN_model\")"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[INFO] serializing network and label binarizer...\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i5AKoXf5rIC-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# make prediction\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import load_model\n",
    "# import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "# load the input image and resize it to the target spatial dimensions\n",
    "width = 64\n",
    "height = 64\n",
    "image = cv2.imread(\"gdrive/data_try_1/flex_h.png\")\n",
    "output = image.copy()\n",
    "image = cv2.resize(image, (width, height))\n",
    "\n",
    "# scale the pixel values to [0, 1]\n",
    "image = image.astype(\"float\") / 255.0\n",
    "\n",
    "# when working with a CNN: don't flatten the image, simply add the batch dimension\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "# # load the model and label binarizer\n",
    "# print(\"[INFO] loading network and label binarizer...\")\n",
    "# model = load_model('first_CNN_model')\n",
    "# lb = pickle.loads(open(\"first_CNN_model_label_bin\", \"rb\").read())\n",
    "\n",
    "# make a prediction on the image\n",
    "preds = model.predict(image)\n",
    "\n",
    "# find the class label index with the largest corresponding probability\n",
    "i = preds.argmax(axis=1)[0]\n",
    "label = lb.classes_[i]\n",
    "\n",
    "# draw the class label + probability on the output image\n",
    "# text = \"{}: {:.1f}%\".format(label, preds[0][i] * 100)\n",
    "# cv2.putText(output, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "# show the output image\n",
    "# cv2.imshow(\"Image\", output)\n",
    "# cv2.waitKey(0)   # Delay in milliseconds. 0 is the special value that means “forever”, until you close the image window"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yP16DdtlrIDE",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "4a2b1c51-dbc6-4e19-b8bc-4222c4330619",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1582830630720,
     "user_tz": -300,
     "elapsed": 739,
     "user": {
      "displayName": "Asim Sansi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAAZ4EyKPTwdHk0nOLcOIoJ_-cTjRZOwqQX9hnZPg=s64",
      "userId": "09155861121300441680"
     }
    }
   },
   "source": [
    "label"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ul'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 38
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3ItC-cjVrIDJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from keras.models import load_model\n",
    "# import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "md=load_model('first_CNN_model')\n",
    "lb=open(\"first_CNN_model_label_bin\", \"r\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4__zxvqCrIDN",
    "colab_type": "code",
    "colab": {},
    "outputId": "05f0c249-0606-4853-fab9-dbf2b93ce933"
   },
   "source": [
    "lb"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='first_CNN_model_label_bin' mode='r' encoding='cp1252'>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ge-ICl4grIDV",
    "colab_type": "code",
    "colab": {},
    "outputId": "9e244b08-0aa0-48e9-e094-81cda247cf88"
   },
   "source": [
    "width = 64\n",
    "height = 64\n",
    "image = cv2.imread(\"imgelec/screen.JPG\")\n",
    "output = image.copy()\n",
    "image = cv2.resize(image, (width, height))\n",
    "# scale the pixel values to [0, 1]\n",
    "image = image.astype(\"float\") / 255.0\n",
    "\n",
    "# when working with a CNN: don't flatten the image, simply add the batch dimension\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "preds = md.predict(image)\n",
    "\n",
    "# find the class label index with the largest corresponding probability\n",
    "#i = preds.argmax(axis=1)[0]\n",
    "#label = lb.classes_[i]\n",
    "print(preds)\n",
    "probas = np.array(preds)\n",
    "labels = np.argmax(probas, axis=-1)\n",
    "print(labels)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[2.5435902e-06 6.3055629e-01 3.6944112e-01]]\n",
      "[1]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tL12Q7gdrIDb",
    "colab_type": "code",
    "colab": {},
    "outputId": "2b1d60ab-225d-41a5-a396-8f3fbabd76ea"
   },
   "source": [
    "# plot the prediction probability for each category\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = [10,5])   # [width, height]\n",
    "\n",
    "x = [ lb.classes_[0], lb.classes_[1], lb.classes_[2] ]\n",
    "y = [ preds[0][0], preds[0][1], preds[0][2] ]\n",
    "plt.barh(x, y, color='violet')\n",
    "\n",
    "ticks_x = np.linspace(0, 1, 11)   # (start, end, number of ticks)\n",
    "plt.xticks(ticks_x, fontsize=10, family='fantasy', color='black')\n",
    "plt.yticks( size=15, color='navy' )\n",
    "for i, v in enumerate(y):\n",
    "    plt.text(v, i, \"  \"+str((v*100).round(1))+\"%\", color='blue', va='center', fontweight=None)\n",
    "\n",
    "plt.title('Prediction Probability', family='serif', fontsize=15, style='italic', weight='bold', color='olive', loc='center', rotation=0)\n",
    "plt.xlabel('Probability', fontsize=12, weight='bold', color='blue')\n",
    "plt.ylabel('Category', fontsize=12, weight='bold', color='indigo')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-17930ee0fb7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'violet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Xx4XOTKrIDi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          Cat       0.67      0.73      0.70       189\n",
    "#          Dog       0.69      0.64      0.66       193\n",
    "#        Panda       0.92      0.90      0.91       218\n",
    "\n",
    "#    micro avg       0.76      0.76      0.76       600\n",
    "#    macro avg       0.76      0.76      0.76       600\n",
    "# weighted avg       0.77      0.76      0.76       600"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "33_wpvOVrIDo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          Cat       0.63      0.80      0.71       189\n",
    "#          Dog       0.71      0.52      0.60       193\n",
    "#        Panda       0.90      0.91      0.91       218\n",
    "\n",
    "#    micro avg       0.75      0.75      0.75       600\n",
    "#    macro avg       0.75      0.74      0.74       600\n",
    "# weighted avg       0.76      0.75      0.74       600"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya9R8449rIDu",
    "colab_type": "text"
   },
   "source": [
    "Correct prediction!\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3Z_orF7rIDv",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJg7TF75rIDy",
    "colab_type": "text"
   },
   "source": [
    "Correct prediction!\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSIJB_ovrID0",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPycCIuprID2",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CSVJJlWrID4",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgxsS1rdrID6",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0il4MRgwrID7",
    "colab_type": "text"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOk7z27orIEH",
    "colab_type": "text"
   },
   "source": [
    "# Conclusion:\n",
    "Convolutional Neural Network is able to obtain higher accuracy than a standard fully-connected network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hEA_ejhdrIEJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "        "
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}